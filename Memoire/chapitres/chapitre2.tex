\chapter{État de l'art}
\label{chap:2}

La détection et la reconnaissance de véhicules militaires sont des domaines de recherche essentiels en intelligence artificielle, en particulier dans le contexte de la défense. Avec l'évolution rapide des technologies de deep learning, plusieurs études ont exploré et développé des modèles visant à améliorer la précision et la robustesse de ces systèmes. Cet état de l'art analyse les articles pertinents sur le sujet, compare les approches existantes et identifie les principaux défis techniques associés à la détection de véhicules militaires.

\section{Articles étudiés}

Plusieurs articles ont été examinés pour comprendre les différentes approches de détection de véhicules militaires. Parmi eux, trois publications se distinguent par la qualité et la pertinence de leurs contributions :

\begin{itemize}
    \item Kamran et al. (2020) \cite{kamran2020}, qui explore l'utilisation de réseaux de neurones convolutifs pour la détection automatisée de véhicules militaires à partir d'images aériennes.
    \item Gupta et al. (2021) \cite{gupta2021}, qui examine l'application de techniques de deep learning pour la détection de véhicules dans des images aériennes, en mettant un accent particulier sur l'amélioration des modèles existants.
    \item Dijk et al. (2020) \cite{spie2020}, qui se concentre sur la détection longue distance de personnes et de véhicules, en analysant les performances de différents modèles de deep learning.
\end{itemize}

Ces articles fournissent une base solide pour comparer les différentes approches et comprendre les enjeux techniques de la détection de véhicules militaires.



\section{Technologies de détection d'objets dans les Images}

La détection d'objets dans les images a évolué rapidement avec l'avènement des techniques de deep learning. Traditionnellement, les méthodes de détection reposaient sur des techniques de traitement d'image basées sur des caractéristiques définies manuellement, telles que les transformées de Hough, les descripteurs de contours et les filtres de Sobel. Cependant, ces méthodes ont montré des limites importantes en termes de précision et de robustesse, particulièrement dans des environnements complexes où les objets peuvent varier en taille, orientation et conditions d'éclairage.

Avec l'émergence des \textbf{réseaux de neurones convolutifs} (CNN), une nouvelle ère a commencé pour la détection d'objets (Figure~\ref{fig:inptu-Output-image}). Les modèles CNN, tels que YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector), et Faster R-CNN, ont permis de franchir un cap en matière de précision et d'efficacité, en apprenant directement des données d'entraînement pour extraire des caractéristiques complexes adaptées aux spécificités des objets présents dans les images \cite{kamran2020, gupta2021}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/input-image.png}
        \caption{Image d'entrée : contenant des véhicules}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/output-image.png}
        \caption{Image de sortie : Reconnaissance des véhicules}
    \end{subfigure}
    \caption{Images aériennes à basse altitude de véhicules réels \cite[p.~3]{kamran2020}.}
    \label{fig:inptu-Output-image}
\end{figure}

\textbf{YOLOv3} \cite{redmon2016yolo} est particulièrement notable pour sa rapidité et son efficacité dans les applications en temps réel. Contrairement à d'autres modèles, YOLOv3 divise l'image en une grille et prédit simultanément plusieurs boîtes englobantes et leurs probabilités de classe, ce qui le rend extrêmement rapide. Cependant, cette rapidité se fait parfois au détriment de la précision, surtout pour les objets de petite taille ou partiellement occultés. Néanmoins, YOLOv3 reste un choix privilégié pour les applications nécessitant une détection rapide avec une précision acceptable, que ce soit pour des images capturées à partir d'une caméra embarquée, de vidéosurveillance, ou de systèmes aéroportés \cite{gupta2021}.

\textbf{SSD} \cite{liu2016ssd} offre également une approche rapide mais légèrement plus précise que YOLO pour les objets de taille moyenne à grande. SSD divise l'image en plusieurs couches de caractéristiques, chacune spécialisée dans la détection d'objets de différentes tailles, ce qui améliore la précision tout en conservant une bonne vitesse d'inférence. Ce modèle est adapté à une grande variété d'applications, qu'il s'agisse de la surveillance vidéo, de la détection de véhicules dans des environnements urbains, ou de l'analyse d'images capturées par des drones \cite{kamran2020}.

Enfin, le modèle \textbf{Faster R-CNN} \cite{girshick2016rcnn} se distingue par son excellente précision, en particulier dans des environnements complexes avec des objets de petite taille ou partiellement cachés. Ce modèle utilise un réseau de propositions de régions pour localiser les zones d'intérêt avant d'appliquer la classification, offrant ainsi une détection plus précise. Toutefois, cette méthode exige davantage de ressources computationnelles, ce qui la rend moins adaptée aux environnements nécessitant des temps de réponse rapides, comme dans les applications en temps réel avec des exigences élevées en termes de précision \cite{kamran2020}.

L'application de ces modèles aux images, qu'elles soient issues de drones, de caméras de surveillance ou d'autres sources, présente des défis uniques. Les objets détectés peuvent être de petite taille, camouflés ou situés dans des environnements visuellement encombrés. Ces facteurs compliquent la tâche des algorithmes de détection classiques, nécessitant des ajustements spécifiques dans les architectures de réseaux neuronaux et les techniques de prétraitement des données \cite{gupta2021}.

De plus, l'utilisation de \textbf{datasets spécialisés} est importante pour entraîner ces modèles à détecter des objets dans des contextes variés. Par exemple, Kamran et al. \cite{kamran2020} ont développé un dataset spécifique pour la détection de véhicules militaires, combinant des images réelles et synthétiques, ce qui permet de pallier le manque de données réelles disponibles pour l'entraînement des modèles.

Enfin, les techniques de \textbf{génération de données synthétiques}, comme celles basées sur les GANs (Generative Adversarial Networks), sont de plus en plus utilisées pour enrichir les datasets et améliorer la robustesse des modèles de détection face à la variabilité des conditions d'acquisition des images, qu'il s'agisse d'images de terrain, aériennes ou issues de caméras fixes \cite{spie2020}.

\begin{figure}[H]
    \center
    \includegraphics[width=\textwidth]{./images/category-images.png}
    \caption{Quelques catégories d'images \cite[p.~5]{kamran2020}.}
    \label{fig:comparaison_vehicles}
\end{figure}


\section{Détection de véhicules militaires}

\subsection{Enjeux et défis spécifiques}

La détection de véhicules militaires dans les images aériennes pose des défis particuliers qui ne sont pas rencontrés dans la détection de véhicules civils. Ces défis incluent le camouflage actif, la dissimulation dans des environnements naturels complexes, et la variabilité des configurations de véhicules militaires. Contrairement aux véhicules civils, les véhicules militaires peuvent varier considérablement en termes de taille, de forme et de coloration, ce qui complique davantage leur détection \cite{kamran2020}.

En outre, les véhicules militaires sont souvent capturés dans des conditions difficiles, telles que des angles de vue inhabituels (ex. la Figure~\ref{fig:comparaison_vehicles} des images aériennes prises à basse altitude), des environnements à faible luminosité, ou des contextes où les véhicules sont partiellement cachés ou occultés par d'autres objets. Ces scénarios augmentent la difficulté de la détection, nécessitant des algorithmes capables de gérer ces complexités.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/1-military-vehicul.png}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/1-military-vehicul-2.png}
        \caption{}
    \end{subfigure}
    \caption{Images aériennes à basse altitude de véhicules réels \cite[p.~2]{kamran2020}.}
    \label{fig:comparaison_vehicles}
\end{figure}


\subsection{Techniques actuelles pour l'identification des véhicules militaires}

Les approches modernes pour la détection des véhicules militaires utilisent principalement des techniques de deep learning, avec un accent sur les réseaux de neurones convolutifs (CNN). Quatre architectures principales sont souvent utilisées pour cette tâche : \textbf{Faster R-CNN}, \textbf{YOLOv3}, \textbf{R-FCN} (Region-based Fully Convolutional Networks), et \textbf{SSD} (Single Shot MultiBox Detector). Ces architectures ont montré leur efficacité pour détecter et classifier les véhicules militaires, même dans des environnements complexes et encombrés \cite{kamran2020, gupta2021}.

Parmi ces architectures, Faster R-CNN a démontré une supériorité dans plusieurs études en raison de sa capacité à générer rapidement des propositions de régions et à classifier les objets avec une grande précision. Cependant, pour des véhicules de petite taille ou dans des contextes de faible contraste, des ajustements spécifiques des hyperparamètres et des techniques de data augmentation sont souvent nécessaires pour améliorer les performances des modèles \cite{gupta2021}.

YOLOv3, de son côté, est favorisé pour les applications nécessitant une détection rapide et est capable de traiter des images en temps réel, ce qui est important dans des environnements où la rapidité d'intervention est primordiale. Bien que YOLOv3 soit légèrement moins précis que Faster R-CNN pour les objets de petite taille, il offre un bon compromis entre vitesse et précision dans des scénarios militaires \cite{gupta2021}.

L'utilisation de \textbf{datasets spécialisés} est également importante. Par exemple, Kamran et al. \cite{kamran2020} ont développé un dataset spécifique pour la détection de véhicules militaires à partir d'images aériennes prises à basse altitude. Ce dataset combine des images réelles et des images synthétiques, permettant ainsi de pallier le manque de données réelles disponibles pour l'entraînement des modèles.

Enfin, les techniques de \textbf{génération de données synthétiques}, comme celles basées sur les GANs, sont de plus en plus utilisées pour enrichir les datasets et améliorer la robustesse des modèles de détection face à la variabilité des conditions d'acquisition des images \cite{spie2020}.


\section{Augmentation de données}

La quantité et de la qualité des données d'apprentissage ont un impact majeur sur la précision et l’efficacité des algorithmes du Deep Learning pour des tâches telles que la reconnaissance d'images, la segmentation d'images, la détection d'objets, etc.
Et même si nous sommes dans l’ère du Big data, la quantité des données disponible pour l'optimisation des ces algorithmes est parfois insuffisante.

\begin{figure}[H]
    \center
    \includegraphics[width=\textwidth]{./images/transfo_combi.png}
    \caption{Un exemple d'application d'une combinaison de transformations.}
    \label{fig:exemple_transfo}
\end{figure}


\noindent Il existe plusieurs outils permettant d'augmenter des données.

\subsection{Données augmentées}

Les données augmentées proviennent de données originales, auxquelles ont été appliquées des transformations mineures (comme la rotation d’une image ou l’ajout de bruit à une vidéo).

Certaines techniques de transformation d’images couramment utilisées sont : \textbf{renversement, rotation, recadrage, ajustement de la luminosité, ajout de bruit}.

\subsubsection{Scikit-image}
C'est un package Python open source qui fonctionne avec des tableaux Numpy. Il implémente des algorithmes et des utilitaires destinés à être utilisés dans la recherche, l'éducation et les applications industrielles.
Il s'agit d'une bibliothèque assez simple et intuitive, même pour ceux qui découvrent l'écosystème Python. Le code est de haute qualité et évalué par des pairs, écrit par une communauté active de bénévoles.

\subsubsection{OpenCV-Python}
OpenCV-Python (Open Source Computer Vision Library) est non seulement rapide (puisque l'arrière-plan est constitué de code écrit en C/C++), mais il est également facile à coder et à déployer (grâce au wrapper Python au premier plan).
Cela en fait un excellent choix pour exécuter des programmes à forte intensité de calcul.

\subsubsection{Albumentations}
Albumentations est une bibliothèque d'augmentation d'image rapide et un wrapper facile à utiliser autour d'autres bibliothèques. Elle est basée sur Numpy, OpenCV, et imgaug, en choisissant le meilleur de chacun d’eux.
Elle a été écrite par des compétiteurs sur Kaggle et a été utilisée pour obtenir d'excellents résultats dans de nombreuses compétitions de Deep Learning sur Kaggle, Topcoder, CVPR, et MICCAI.

\subsection{Données synthétiques}

Les données synthétiques sont générées artificiellement sans référence directe au monde réel.
La plupart du temps, elles sont produites par des réseaux génératifs adverses (GANs) ou des modèles de diffusion.

\subsubsection{DreamBooth}
DreamBooth est une technique d'apprentissage qui met à jour l'ensemble d’un modèle de diffusion en s'entraînant sur seulement quelques images d'un sujet ou d'un style spécifique.
Elle fonctionne en associant un mot spécial dans un prompt avec quelques exemples d'images pour permettre la personnalisation de la génération d'images \cite{ruiz2023dreambooth}.


\subsubsection{Stable Diffusion}
Stable Diffusion est une autre technique d'apprentissage pour la génération d'images synthétiques.
Elle permet de générer des images réalistes à partir de textes descriptifs (Text-to-Image), en se basant sur un modèle de diffusion entraîné sur un très large ensemble de données d'images.
Ce modèle est ouvert et permet des ajustements et des personnalisations pour diverses applications, y compris l'intégration de nouveaux concepts à partir d'ensembles d'images spécifiques.

Ci-dessous, nous avons deux graphes présentant les scores de quelques versions du modèle Stable Diffusion:

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/graph-sdv1.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./images/graph-sdv2.jpg}
        \caption{}
    \end{subfigure}
    \caption{Évaluations avec différentes version de Stable Diffusion. \cite{rombach2021highresolution}}
    \label{fig:comparaison_sd}
\end{figure}


Sur ce schéma, nous présentons une trame de fonctionnement du modèle text2image
\begin{figure}[H]
    \center
    \includegraphics[width=\textwidth]{./images/shema_sd.png}
    \caption{Schéma du fonctionnement normal de Stable Diffusion}
\end{figure}


\subsubsection{LoRA (Low-Rank Adaptation)}
LoRA est une méthode d'adaptation fine qui permet de fine-tuner un modèle de diffusion sans avoir à modifier l'ensemble des poids du modèle.
Elle permet une adaptation plus légère et plus rapide du modèle en ajoutant des couches d'apprentissage réduites (low-rank layers) à l'architecture existante.
Cette méthode est particulièrement efficace pour personnaliser des modèles comme Stable Diffusion sur de nouveaux jeux de données sans nécessiter autant de ressources computationnelles que DreamBooth.


\section{Étude comparative des approches}

\subsection{Valeur des modèles}

Les articles analysés mettent en évidence l'efficacité des modèles de deep learning, en particulier des réseaux de neurones convolutifs (CNN), dans la détection de véhicules militaires. Les études de Kamran et al. \cite{kamran2020} et de Gupta et al. \cite{gupta2021} démontrent que les modèles comme YOLO et Faster R-CNN surpassent largement les méthodes traditionnelles en termes de précision et de rapidité de détection.

Toutefois, une analyse plus approfondie montre que chaque modèle présente des forces et des faiblesses. Par exemple, \textbf{YOLOv3} est particulièrement performant en temps réel, mais il peut manquer de précision lorsqu'il s'agit de petits objets ou d'éléments partiellement dissimulés. À l'inverse, \textbf{Faster R-CNN} se distingue par une meilleure précision, mais exige davantage de ressources informatiques, ce qui le rend moins approprié dans les environnements où ces dernières sont limitées.

\subsection{Qualité des données et entraînement des modèles}

L'efficacité des modèles de deep learning dépend fortement de la qualité et de la quantité des données utilisées pour leur entraînement. Kamran et al. \cite{kamran2020} soulignent l'importance de disposer de datasets spécialisés, comprenant à la fois des images réelles et synthétiques, pour pallier le manque de données disponibles. Dans le même temps, Gupta et al. \cite{gupta2021} montrent que l'utilisation de techniques de data augmentation est importante pour améliorer la robustesse des modèles face aux variations des conditions d'acquisition des images.

La génération de données synthétiques, notamment via des GANs, est également discutée comme une solution viable pour enrichir les datasets et permettre aux modèles de mieux généraliser. Cependant, cette approche introduit de nouveaux défis, notamment en termes de validation des modèles sur des données réelles.

\subsection{Modèles utilisés et performances}

Les performances des différents modèles sont évaluées en fonction de critères tels que la précision de la détection, le taux de faux positifs, et la robustesse face aux variations d'éclairage et de perspective. L'étude de Dijk et al. \cite{spie2020} compare les performances de plusieurs modèles sur des images à longue distance, montrant que les modèles comme \textbf{R-FCN} peuvent offrir un bon compromis entre précision et vitesse dans des environnements complexes.

Néanmoins, la comparaison entre les modèles met également en lumière le besoin d'optimiser les hyperparamètres pour chaque contexte spécifique. Par exemple, l'ajustement des seuils de détection et l'utilisation de techniques de régularisation sont souvent nécessaires pour améliorer les performances dans des conditions de faible visibilité.

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|p{3.1cm}|p{2.1cm}|p{1.1cm}|p{2.2cm}|X|c|}
        \hline
        \textbf{Étude}                  & \textbf{Modèle} & \textbf{mAP (\%)} & \textbf{Temps d'inférence (ms)} & \textbf{Données}                & \textbf{Classes} \\ \hline
        Kamran et al. \cite{kamran2020} & Faster R-CNN    & 78                & 220                             & 15 086 (vehicules et personnes) & 3                \\ \hline
        Kamran et al. \cite{kamran2020} & SSD             & 72                & 165                             & 15 086 (vehicules et personnes) & 3                \\ \hline
        Gupta et al. \cite{gupta2021}   & YOLOv3          & 82                & 180                             & 6 772  (vehicules)              & 5                \\ \hline
        Gupta et al. \cite{gupta2021}   & SSD             & 75                & 160                             & 6 772  (vehicules)              & 5                \\ \hline
        Dijk et al. \cite{spie2020}     & CNN             & 55                & 250                             & 7 920  (vehicules)              & 7                \\ \hline
    \end{tabularx}
    \caption{Comparaison des performances des modèles}
    \label{tab:comparaison}
\end{table}

\subsection{Paramètres de configuration des modèles}

Les performances des modèles de deep learning dépendent fortement des paramètres de configuration utilisés pendant l'entraînement. Dans cette section, nous comparons les principaux paramètres de configuration pour les modèles étudiés dans les différents articles.

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{3cm}|p{2cm}|}
        \hline
        \textbf{Étude}                  & \textbf{Modèle} & \textbf{Taux d'apprentissage} & \textbf{Taille du batch} & \textbf{Nombre d'époques} & \textbf{Taille d'image (px)} \\ \hline
        Kamran et al. \cite{kamran2020} & Faster R-CNN    & 0.001                         & 16                       & 50                        & 600x600                      \\ \hline
        Kamran et al. \cite{kamran2020} & SSD             & 0.002                         & 32                       & 100                       & 300x300                      \\ \hline
        Gupta et al. \cite{gupta2021}   & YOLOv3          & 0.0001                        & 32                       & 70                        & 416x416                      \\ \hline
        Gupta et al. \cite{gupta2021}   & SSD             & 0.002                         & 24                       & 100                       & 300x300                      \\ \hline
        Dijk et al. \cite{spie2020}     & CNN             & 0.0005                        & 24                       & 80                        & 512x512                      \\ \hline
    \end{tabularx}
    \caption{Comparaison des paramètres de configuration des modèles}
    \label{tab:parametres}
\end{table}

Les paramètres de configuration ci-dessus montrent les choix effectués par les auteurs pour optimiser les performances des modèles dans des contextes spécifiques. Par exemple, la taille du batch et le taux d'apprentissage sont importants pour la stabilité et la convergence du modèle. Dans l'étude de Kamran et al., un taux d'apprentissage plus élevé a été utilisé pour SSD, ce qui a permis d'accélérer l'entraînement, bien que cela puisse parfois mener à une instabilité si non contrôlé par un ajustement fin des hyperparamètres. En revanche, Gupta et al. ont opté pour un taux d'apprentissage plus faible pour YOLOv3, privilégiant une convergence plus lente mais plus stable, ce qui est souvent nécessaire pour des architectures complexes comme YOLOv3.

Cette comparaison met en évidence l'importance d'ajuster les paramètres en fonction des spécificités du modèle et du contexte opérationnel, afin de maximiser les performances tout en minimisant les risques d'overfitting ou de sous-apprentissage.

\section{Synthèse}

L'analyse des articles révèle plusieurs défis techniques associés à la détection de véhicules militaires. Parmi eux, la gestion des données limitées et leur qualité, l'optimisation des modèles pour des environnements variés, et la réduction des biais introduits par les datasets sont les plus critiques.

Un aspect essentiel mis en évidence par les recherches est le besoin de trouver un équilibre entre la précision et l'efficacité des calculs. Même si des modèles plus sophistiqués, tels que \textit{YOLOv3}, permettent d'obtenir de meilleures performances, leur utilisation en temps réel dans des contextes militaires est souvent contrainte par les ressources disponibles. Par conséquent, il est souvent nécessaire de faire des compromis selon les besoins spécifiques de la mission.

Les défis spécifiques de la détection de véhicules militaires nécessitent l'utilisation de techniques avancées de deep learning et de datasets spécialisés. Les progrès récents dans ce domaine, combinés à l'utilisation de données synthétiques et de méthodes de data augmentation, offrent des perspectives prometteuses pour améliorer la précision et la robustesse des systèmes de détection dans des contextes militaires complexes.
